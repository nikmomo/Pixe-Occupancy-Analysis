{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviornment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU will be used: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "# import torch\n",
    "import numba\n",
    "from numba import jit, cuda\n",
    "# import torchvision.models as models\n",
    "# from torch import nn, optim\n",
    "# import timm \n",
    "\n",
    "# multi-threading\n",
    "import concurrent.futures\n",
    "\n",
    "# max depth of the image\n",
    "max_depth = 100.0\n",
    "\n",
    "# Use half of cpu for multi-threading tasks\n",
    "# Consider use gpu if CUDA is available\n",
    "num_workers = os.cpu_count() / 2\n",
    "print(\"Number of CPU will be used:\", num_workers)\n",
    "\n",
    "weight_data = 'Data/final_mapping_original.csv'\n",
    "\n",
    "# cuda_available = torch.cuda.is_available()\n",
    "# print(\"CUDA available:\", cuda_available)\n",
    "# if cuda_available:\n",
    "#     print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Filtering out background\n",
    "\n",
    "Filter out all background and leave a pure pig depth image to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_filter(file_addr):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(file_addr)\n",
    "\n",
    "    # Adjust GMM parameters\n",
    "    backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "    fgMask = backSub.apply(image)\n",
    "\n",
    "    # Refine the foreground mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    fgMask = cv2.erode(fgMask, kernel, iterations=2)\n",
    "    fgMask = cv2.dilate(fgMask, kernel, iterations=2)\n",
    "\n",
    "    # Convert image to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color range for the pig color\n",
    "    lower_color = np.array([110, 255, 254])\n",
    "    upper_color = np.array([255, 255, 255])\n",
    "    color_mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Combine color mask with foreground mask\n",
    "    fgMask = cv2.bitwise_and(fgMask, color_mask)\n",
    "\n",
    "    # Find contours from the mask\n",
    "    contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the pig and create a mask for it\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        refined_mask = np.zeros_like(fgMask)\n",
    "        cv2.fillPoly(refined_mask, [largest_contour], 255)\n",
    "        fgMask = refined_mask\n",
    "\n",
    "    # Extract the foreground using the refined mask\n",
    "    foreground = cv2.bitwise_and(image, image, mask=fgMask)\n",
    "    \n",
    "    return foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the filter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_4780.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_3223.png' # Good example\n",
    "# eg_img = 'Data/Week2/20211003/20211003_3342a/_Depth_4489.png' # not that bad example\n",
    "eg_img = 'Data/Week1/20210922/20210922_3342/_Depth_5395.png' # Bad example\n",
    "foreground = img_filter(eg_img)\n",
    "\n",
    "# image = cv2.imread(eg_img)\n",
    "# # print(\"Total number of pixels after filtering:\", image.shape[0] * image.shape[1])\n",
    "# cv2.imshow('Original image', image)\n",
    "# cv2.imshow('After filtering', foreground)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Count pixels\n",
    "\n",
    "Count the pixels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_map(img):\n",
    "\n",
    "    # Convert the foreground to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Flatten the image\n",
    "    pixels = img.reshape(-1, img.shape[-1])\n",
    "\n",
    "    # Count unique colors\n",
    "    unique_colors, counts = np.unique(pixels[pixels.sum(axis=1) != 0], axis=0, return_counts=True)\n",
    "\n",
    "    # Create a color map\n",
    "    color_map = {tuple(color): count for color, count in zip(unique_colors, counts)}\n",
    "    \n",
    "    return color_map\n",
    "\n",
    "def get_total_heights(img):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize the depth values (assuming 8-bit image and max depth of 10 meters)\n",
    "    # You will need to adjust the max_depth to match the actual range of your sensor\n",
    "    \n",
    "    normalized_depth_image = (gray_image / 255.0) * max_depth\n",
    "    \n",
    "    total_height = np.sum(normalized_depth_image)\n",
    "    \n",
    "    # cv2.imshow('Image', normalized_depth_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return total_height\n",
    "\n",
    "def get_mean_heights(img):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize the depth values (assuming 8-bit image and max depth of 10 meters)\n",
    "    # You will need to adjust the max_depth to match the actual range of your sensor\n",
    "    \n",
    "    normalized_depth_image = (gray_image / 255.0) * max_depth\n",
    "    \n",
    "    mean_height = np.sum(normalized_depth_image) / np.count_nonzero(normalized_depth_image)\n",
    "    \n",
    "    cv2.imshow('grayscale image', gray_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return mean_height\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test counting pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_img = 'Data/Week2/20211002/20211002_3342/_Depth_4780.png'\n",
    "foreground = img_filter(eg_img)\n",
    "# total_heights = get_total_heights(foreground)\n",
    "# mean_heights = get_mean_heights(foreground)\n",
    "color_map = get_pixel_map(foreground)\n",
    "# print(\"Total number of pixels in map:\", sum(color_map.values()))\n",
    "# print(\"Color Map:\", color_map)\n",
    "# print(\"Mean height: \", mean_heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Streamline processing all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_data(row):\n",
    "    image_path = 'Data/' + row[0]\n",
    "    base_name, _ = os.path.splitext(image_path)\n",
    "    image_path = f'{base_name}.png' # Change from jpg to png\n",
    "    # print(image_path)\n",
    "    \n",
    "    # if using whole image files, use this one\n",
    "    if not os.path.exists(image_path): \n",
    "        # print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get the foreground by calling img_filter\n",
    "    foreground = img_filter(image_path)\n",
    "    \n",
    "    # Get the pixel map by calling get_pixel_map\n",
    "    color_map = get_pixel_map(foreground)\n",
    "    \n",
    "    return {\n",
    "                'weight': row[3],\n",
    "                'image_path': image_path,\n",
    "                'color_map': color_map\n",
    "            }\n",
    "            \n",
    "def get_data():\n",
    "    with open(weight_data, mode='r', newline='') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        # Create a new list to hold the combined data\n",
    "        combined_data = []\n",
    "        headers = next(reader)\n",
    "        \n",
    "        # multi-threading data process\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            # Start a set of tasks and mark each future with its URL\n",
    "            future_to_task = {executor.submit(img_to_data, arg): arg for arg in reader}\n",
    "            for future in concurrent.futures.as_completed(future_to_task):\n",
    "                arg = future_to_task[future]\n",
    "                try:\n",
    "                    data = future.result()\n",
    "                    combined_data.append(data)\n",
    "                except Exception as exc:\n",
    "                    print(f'{arg} generated an exception: {exc}')\n",
    "                # else:\n",
    "                #     print(f'{arg} page is {len(data)} bytes')\n",
    "                \n",
    "    # filter out nonetypes\n",
    "    combined_data = [item for item in combined_data if item is not None and isinstance(item, dict)]\n",
    "    \n",
    "    # Convert the combined data to a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Display the combined DataFrame\n",
    "    # print(combined_df)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Gather all data and export the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "\n",
    "# Expand color_map dictionaries into a new DataFrame\n",
    "color_features = pd.DataFrame.from_records(data['color_map']).fillna(0)\n",
    "\n",
    "# Merge expanded features back with the original DataFrame\n",
    "# Ensure that both dataframes are aligned on the index\n",
    "final_data = data.drop('color_map', axis=1).join(color_features)\n",
    "\n",
    "# print(final_data)\n",
    "csv_file_path = 'Data/data.csv'\n",
    "final_data.to_csv(csv_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
